{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "# <font color='blue'>Gradient Descent Assignment<\/font>\n",
                "The aim of this assignment is to understand the Gradient descent optimization process in more detail. In the previous section on Gradient Descent, we discussed how to implement gradient calculation and weight update for a single variable ( `m` ) using simple math operations. In this assignment are required to do the same, but for 2 variables. We will use the full form of a line i.e. `y = mx + c`. You need to estimate the values of the two variables `m` and `c` using Stochastic Gradient Descent.\n",
                "\n",
                "You have two tasks:\n",
                "1. `Implement the gradient calculation step for the 2 variables.`\n",
                "2. `Implement the weight update step for the 2 variables.`"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font color='blue'>Marking Scheme<\/font>\n",
                "\n",
                "#### Maximum Points: 30\n",
                "\n",
                "<div>\n",
                "    <table>\n",
                "        <tr><td><h3>Sr. no.<\/h3><\/td> <td><h3>Problem<\/h3><\/td> <td><h3>Points<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>1<\/h3><\/td> <td><h3>Implement Gradients <\/h3><\/td> <td><h3>20<\/h3><\/td> <\/tr>\n",
                "        <tr><td><h3>2<\/h3><\/td> <td><h3>Implement SGD<\/h3><\/td> <td><h3>10<\/h3><\/td> <\/tr>\n",
                "    <\/table>\n",
                "<\/div>\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "import torch\n",
                "import matplotlib.pyplot as plt\n",
                "%matplotlib inline\n",
                "\n",
                "plt.style.use('ggplot')\n",
                "\n",
                "torch.manual_seed(0)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "plt.rcParams[\"figure.figsize\"] = (15, 8)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:blue\">Generate Data <\/font>\n",
                "We will generate 1000 data points for the experiment. The x axis is the independent variable which has values randomly distributed between -5 to 5. We assume some values for m and c to create the data points for the dependent variable ( y-axis ). We also add some randomness so that the y values are different for the same x. \n",
                "\n",
                "Now, we have a simple dataset which has been generated using a linear model in the presence of noise. The data has been dispayed using the scatter plot."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Generating y = mx + c + random noise\n",
                "num_data = 1000\n",
                "\n",
                "# True values of m and c\n",
                "m_line = 3.3\n",
                "c_line = 5.3\n",
                "\n",
                "# input (Generate random data between [-5,5])\n",
                "x = 10 * torch.rand(num_data) - 5\n",
                "\n",
                "# Output (Generate data assuming y = mx + c + noise)\n",
                "y_label = m_line * x + c_line + torch.randn_like(x)\n",
                "y = m_line * x + c_line\n",
                "\n",
                "# Plot the generated data points \n",
                "plt.plot(x, y_label, '.', color='g', label=\"Data points\")\n",
                "plt.plot(x, y, color='b', label='y = mx + c', linewidth=3)\n",
                "plt.ylabel('y')\n",
                "plt.xlabel('x')\n",
                "plt.legend()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "The goal is to predict $y$ given some value of $x$. To do this we will fit a line that goes through the data points $(x_i, y_i)$. The equation for such a line is \n",
                "\n",
                "$$\n",
                "y = mx + c\n",
                "$$\n",
                "\n",
                "We have a set of data points $(x_i, y_i)$, and they should all satisfy the equation above. i.e., \n",
                "\n",
                "$$\n",
                "y_i = m x_i + c\n",
                "$$\n",
                "\n",
                "Unless we have perfect data with no noise, even the best $m$ and $c$ we can find will not perfectly fit the data. So, we will have an **error** or a **residual** given by\n",
                "\n",
                "$$\n",
                "e_i = (y_i - m x_i -c) \n",
                "$$\n",
                "\n",
                "We want to find a value of $m$ and $c$ that minimizes the error above. Positive or negative values of error are equally bad for us. So, we are interested in mimimizing the square of the error above. In addition, we want to mimimize the squared error over all the data points.\n",
                "\n",
                "In other words, we want to mimize a function of the residual that takes the following form\n",
                "\n",
                "$$\n",
                "l_{sse} = \\sum^N_{i=1}(y_i - m x_i -c)^2 \\\\\n",
                "$$\n",
                "\n",
                "This function is called the **loss function**. The sum of squared errors is just one type of loss function. Another extension of this can be the `mean squared error` function which is given by\n",
                "$$\n",
                "l_{mse} = \\frac{1}{N}\\sum^N_{i=1}(y_i - m x_i -c)^2 \\\\\n",
                "$$\n",
                "\n",
                "It is simply the mean of squared error discussed above.\n",
                "\n",
                "There are other types of loss functions which will learn about later in the course. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:blue\">Gradient Descent (30 Points)<\/font>\n",
                "\n",
                "We have already seen how the math works for `m`. The same approach applies to the case for `m` and `c`. \n",
                "\n",
                "We calculate the loss function and then take partial derivatives w.r.t `m` and `c` respectively.\n",
                "$$\n",
                "\\begin{align}\n",
                "l &= \\sum^n_{i=1}(y_i - m x_i - c)^2 \\\\\n",
                "\\frac{\\partial l}{\\partial m}  &= -2 \\sum^n_{i=1} x_i(y_i - m x_i - c) \\\\\n",
                "\\frac{\\partial l}{\\partial c}  &= -2 \\sum^n_{i=1} (y_i - m x_i - c) \\\\\n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "\n",
                "To follow the slope of the curve, we need to move m in the direction of negative gradient. However, we need to control the rate at which we go down the slope so that we do not overshoot the minimum. So we use a parameter $\\lambda$ called the `learning rate`. \n",
                "\n",
                "$$\n",
                "\\begin{align}\n",
                "m_k &= m_{k-1} - \\lambda \\frac{\\partial l}{\\partial m} \\\\\n",
                "c_k &= c_{k-1} - \\lambda \\frac{\\partial l}{\\partial c} \\\\ \n",
                "\\end{align}\n",
                "$$\n",
                "\n",
                "That is it! \n",
                "\n",
                "Let's implement this in code to see that it really works. \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<div class=\"alert alert-block alert-info\">\n",
                "    <b>1. Implement Gradients: 20 Points<\/b>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": [
                "def gradient_wrt_m_and_c(inputs, labels, m, c, k):\n",
                "    \n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    inputs (torch.tensor): input (X)\n",
                "    labels (torch.tensor): label (Y)\n",
                "    m (float): slope of the line\n",
                "    c (float): vertical intercept of line\n",
                "    k (torch.tensor, dtype=int): random index of data points\n",
                "    '''\n",
                "    # gradient w.r.t to m is g_m \n",
                "    # gradient w.r.t to c is g_c\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    \n",
                "    return g_m, g_c"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "k = torch.tensor([0, 2])\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Gradient of m : -24.93\n",
                "Gradient of c : 1.60\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "X = torch.tensor([-0.0374,  2.6822, -4.1152])\n",
                "Y = torch.tensor([ 5.1765, 14.1513, -8.2802])\n",
                "m = 2\n",
                "c = 3\n",
                "k = torch.tensor([0, 2])\n",
                "\n",
                "gm, gc = gradient_wrt_m_and_c(X, Y, m, c, k)\n",
                "\n",
                "print('Gradient of m : {0:.2f}'.format(gm))\n",
                "print('Gradient of c : {0:.2f}'.format(gc))    "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Implement Gradients wrt. m",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "Implement Gradients wrt. c",
                    "locked": true,
                    "points": "10",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "<div class=\"alert alert-block alert-info\">\n",
                "    <b>2. Implement SGD: 10 Points<\/b>\n",
                "<\/div>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "grade_id": "SGD Update of ",
                    "locked": false,
                    "points": "5",
                    "solution": false
                }
            },
            "outputs": [],
            "source": [
                "def update_m_and_c(m, c, g_m, g_c, lr):\n",
                "    '''\n",
                "    All arguments are defined in the training section of this notebook. \n",
                "    This function will be called from the training section.  \n",
                "    So before completing this function go through the whole notebook.\n",
                "    \n",
                "    g_m = gradient w.r.t to m\n",
                "    c_m = gradient w.r.t to c\n",
                "    '''\n",
                "    # update m and c parameters\n",
                "    # store updated value of m is updated_m variable\n",
                "    # store updated value of c is updated_c variable\n",
                "    ###\n",
                "    ### YOUR CODE HERE\n",
                "    ###\n",
                "    return updated_m, updated_c"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "**Test your code before submitting it using the below code cell.**\n",
                "\n",
                "For given input:\n",
                "```\n",
                "m = 2\n",
                "c = 3\n",
                "g_m = -24.93\n",
                "g_c = 1.60\n",
                "lr = 0.001\n",
                "```\n",
                "Output:\n",
                "```\n",
                "Updated m: 2.02\n",
                "Updated c: 3.00\n",
                "```"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "m = 2\n",
                "c = 3\n",
                "g_m = -24.93\n",
                "g_c = 1.60\n",
                "lr = 0.001\n",
                "m, c = update_m_and_c(m, c, g_m, g_c, lr)\n",
                "\n",
                "print('Updated m: {0:.2f}'.format(m))\n",
                "print('Updated c: {0:.2f}'.format(c))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "SGD Update of m",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": true,
                    "grade_id": "SGD Update of c",
                    "locked": true,
                    "points": "5",
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "###\n",
                "### AUTOGRADER TEST - DO NOT REMOVE\n",
                "###\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "source": [
                "## <font style=\"color:blue\">Training<\/font>"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Stochastic Gradient Descent with Minibatch\n",
                "\n",
                "# input \n",
                "X = x\n",
                "\n",
                "# output\/label\n",
                "Y = y_label\n",
                "\n",
                "num_iter = 1000\n",
                "batch_size = 10\n",
                "\n",
                "# display updated values after every 10 iterations\n",
                "display_count = 20\n",
                "# \n",
                "\n",
                "lr = 0.001\n",
                "m = 2\n",
                "c = 1\n",
                "print()\n",
                "loss = []\n",
                "\n",
                "for i in range(0, num_iter):\n",
                "\n",
                "    # Randomly select a training data point\n",
                "    k = torch.randint(0, len(Y)-1, (batch_size,))\n",
                "  \n",
                "    # Calculate gradient of m and c using a mini-batch\n",
                "    g_m, g_c = gradient_wrt_m_and_c(X, Y, m, c, k)\n",
                "    \n",
                "    # update m and c parameters\n",
                "    m, c = update_m_and_c(m, c, g_m, g_c, lr)\n",
                "    \n",
                "    # Calculate Error\n",
                "    e = Y - m * X - c\n",
                "    # Compute Loss Function\n",
                "    current_loss = torch.sum(torch.mul(e,e))\n",
                "    loss.append(current_loss)\n",
                "\n",
                "    if i % display_count==0:\n",
                "        print('Iteration: {}, Loss: {}, updated m: {:.3f}, updated c: {:.3f}'.format(i, loss[i], m, c))\n",
                "        y_pred = m * X + c\n",
                "        # Plot the line corresponding to the learned m and c\n",
                "        plt.plot(x, y_label, '.', color='g')\n",
                "        plt.plot(x, y, color='b', label='Line corresponding to m={0:.2f}, c={1:.2f}'.\n",
                "                 format(m_line, c_line), linewidth=3)\n",
                "        plt.plot(X, y_pred, color='r', label='Line corresponding to m_learned={0:.2f}, c_learned={1:.2f}'.\n",
                "                 format(m, c), linewidth=3)\n",
                "        plt.title(\"Iteration : {}\".format(i))\n",
                "        plt.legend()\n",
                "\n",
                "        plt.ylabel('y')\n",
                "        plt.xlabel('x')\n",
                "        plt.show()\n",
                "        "
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "scrolled": false,
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "print('Loss of after last batch: {}'.format(loss[-1]))\n",
                "print('Leaned \"m\" value: {}'.format( m))\n",
                "print('Leaned \"c\" value: {}'.format( c))\n",
                "\n",
                "# Plot loss vs m  \n",
                "plt.figure\n",
                "plt.plot(range(len(loss)),loss)\n",
                "plt.ylabel('loss')\n",
                "plt.xlabel('iterations')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "lines_to_next_cell": 0,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Calculate the predicted y values using the learned m and c\n",
                "y_pred = m * X + c"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true,
                "nbgrader": {
                    "grade": false,
                    "locked": true,
                    "solution": false
                },
                "editable": false,
                "deletable": false
            },
            "outputs": [],
            "source": [
                "# Plot the line corresponding to the learned m and c\n",
                "plt.plot(x, y_label, '.', color='g', label='X and Y')\n",
                "plt.plot(x, y, color='b', label='Line corresponding to m={0:.2f}, c={1:.2f}'.format(m_line, c_line), linewidth=3)\n",
                "plt.plot(X, y_pred, color='r', label='Line corresponding to m_learned={0:.2f}, c_learned={1:.2f}'.format(m, c), linewidth=3)\n",
                "plt.legend()\n",
                "\n",
                "plt.ylabel('y')\n",
                "plt.xlabel('x')\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "collapsed": true
            },
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.8",
            "language": "python",
            "name": "python38"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text\/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.7"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}