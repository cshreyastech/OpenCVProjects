{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vTlg8FdNKqMq"
   },
   "source": [
    "\n",
    "PyTorch: Custom nn Modules\n",
    "--------------------------\n",
    "\n",
    "A fully-connected ReLU network with one hidden layer, trained to predict y from x\n",
    "by minimizing squared Euclidean distance.\n",
    "\n",
    "This implementation defines the model as a custom Module subclass. Whenever you\n",
    "want a model more complex than a simple sequence of existing Modules you will\n",
    "need to define your model this way.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mYuwGycSKqMr",
    "outputId": "ef5d2460-c83f-4672-8ec2-28de6621a02e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10581.46484375\n",
      "1 9755.71875\n",
      "2 9161.30078125\n",
      "3 8637.4951171875\n",
      "4 8135.08154296875\n",
      "5 7634.916015625\n",
      "6 7127.3212890625\n",
      "7 6610.97021484375\n",
      "8 6087.3720703125\n",
      "9 5563.39599609375\n",
      "10 5048.94873046875\n",
      "11 4551.427734375\n",
      "12 4078.5126953125\n",
      "13 3634.7451171875\n",
      "14 3225.67626953125\n",
      "15 2852.95361328125\n",
      "16 2516.31201171875\n",
      "17 2214.47265625\n",
      "18 1946.53515625\n",
      "19 1709.1043701171875\n",
      "20 1499.0308837890625\n",
      "21 1313.60205078125\n",
      "22 1151.3802490234375\n",
      "23 1009.0332641601562\n",
      "24 883.9778442382812\n",
      "25 774.8359375\n",
      "26 679.2198486328125\n",
      "27 596.10205078125\n",
      "28 524.0062255859375\n",
      "29 462.0333251953125\n",
      "30 410.55902099609375\n",
      "31 370.9833984375\n",
      "32 349.6308288574219\n",
      "33 361.6944580078125\n",
      "34 444.9813232421875\n",
      "35 685.0106811523438\n",
      "36 1272.0538330078125\n",
      "37 2519.06689453125\n",
      "38 4693.54833984375\n",
      "39 6812.6015625\n",
      "40 6350.90185546875\n",
      "41 3024.81298828125\n",
      "42 1011.5364990234375\n",
      "43 448.4580078125\n",
      "44 291.2738037109375\n",
      "45 218.35183715820312\n",
      "46 172.94004821777344\n",
      "47 140.86444091796875\n",
      "48 116.9203872680664\n",
      "49 98.4088134765625\n",
      "50 83.75098419189453\n",
      "51 71.90571594238281\n",
      "52 62.20065689086914\n",
      "53 54.14043045043945\n",
      "54 47.3974494934082\n",
      "55 41.677337646484375\n",
      "56 36.78929138183594\n",
      "57 32.586517333984375\n",
      "58 28.95291519165039\n",
      "59 25.81073570251465\n",
      "60 23.072996139526367\n",
      "61 20.669099807739258\n",
      "62 18.55953598022461\n",
      "63 16.697952270507812\n",
      "64 15.050226211547852\n",
      "65 13.592869758605957\n",
      "66 12.296842575073242\n",
      "67 11.140043258666992\n",
      "68 10.103605270385742\n",
      "69 9.184295654296875\n",
      "70 8.35701847076416\n",
      "71 7.613655090332031\n",
      "72 6.947653770446777\n",
      "73 6.346467018127441\n",
      "74 5.806191444396973\n",
      "75 5.317712306976318\n",
      "76 4.876556873321533\n",
      "77 4.47579288482666\n",
      "78 4.113263130187988\n",
      "79 3.7839279174804688\n",
      "80 3.484642505645752\n",
      "81 3.2112975120544434\n",
      "82 2.963024377822876\n",
      "83 2.7360382080078125\n",
      "84 2.5297114849090576\n",
      "85 2.3397603034973145\n",
      "86 2.1662704944610596\n",
      "87 2.008331537246704\n",
      "88 1.8628108501434326\n",
      "89 1.7291535139083862\n",
      "90 1.6062238216400146\n",
      "91 1.4931291341781616\n",
      "92 1.389509677886963\n",
      "93 1.2936955690383911\n",
      "94 1.2056152820587158\n",
      "95 1.1245211362838745\n",
      "96 1.049109697341919\n",
      "97 0.9797150492668152\n",
      "98 0.9155078530311584\n",
      "99 0.8561532497406006\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Get reproducible results\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define the model\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden_layer_nodes, num_outputs):\n",
    "        # Initialize super class\n",
    "        super().__init__()\n",
    "\n",
    "        # Build model using Sequential container\n",
    "        self.model = nn.Sequential(\n",
    "            # Add hidden layer \n",
    "            nn.Linear(num_inputs, num_hidden_layer_nodes),\n",
    "            # Add ReLU activation\n",
    "            nn.ReLU(),\n",
    "            # Add output layer\n",
    "            nn.Linear(num_hidden_layer_nodes, num_outputs)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass\n",
    "        return self.model(x)\n",
    "\n",
    "# Num data points\n",
    "num_data = 1000\n",
    "\n",
    "# Network parameters\n",
    "num_inputs = 1000\n",
    "num_hidden_layer_nodes = 100\n",
    "num_outputs = 10\n",
    "\n",
    "# Training parameters\n",
    "num_epochs = 100 \n",
    "\n",
    "# Create input and output tensors\n",
    "x = torch.randn(num_data, num_inputs)\n",
    "y = torch.randn(num_data, num_outputs)\n",
    "\n",
    "# Construct model\n",
    "model = MLP(num_inputs, num_hidden_layer_nodes, num_outputs)\n",
    "\n",
    "# Define loss function\n",
    "loss_function = nn.MSELoss(reduction='sum')\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-4)\n",
    "\n",
    "\n",
    "for t in range(num_epochs):\n",
    "\n",
    "    # Forward pass: Compute predicted y by passing x to the model\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Compute and print loss\n",
    "    loss = loss_function(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero gradients, perform a backward pass, and update the weights.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate gradient using backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # Update model parameters (weights)\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
