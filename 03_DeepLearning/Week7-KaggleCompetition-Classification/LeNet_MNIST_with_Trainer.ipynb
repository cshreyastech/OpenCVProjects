{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Combine them all: LeNet5 pipeline with Trainer</font>\n",
    "\n",
    "Let's take a look at how we can build the training pipeline using the Trainer helper class and the other helper classes we've discussed before in this notebook.\n",
    "Import all the necessary classes and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/virtualenvs/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-22 13:14:11.795545: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740258851.809865  433071 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740258851.814152  433071 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 13:14:11.828874: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as Fn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from trainer import Trainer, hooks, configuration\n",
    "from trainer.utils import setup_system, patch_configs\n",
    "from trainer.metrics import AccuracyEstimator\n",
    "from trainer.tensorboard_visualizer import TensorBoardVisualizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from typing import Iterable\n",
    "# from dataclasses import dataclass\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">1. Get Training and Validation Data Loader</font>\n",
    "\n",
    "\n",
    "Define the data wrappers and transformations (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This custom dataset class takes root directory and train flag, \n",
    "    and returns dataset training dataset if train flag is true \n",
    "    else it returns validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, image_shape=None, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        init method of the class.\n",
    "        \n",
    "         Parameters:\n",
    "         \n",
    "         data_root (string): path of root directory.\n",
    "         \n",
    "         train (boolean): True for training dataset and False for test dataset.\n",
    "         \n",
    "         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n",
    "                                             If it is not None image will resize to the given shape.\n",
    "                                 \n",
    "         transform (method): method that will take PIL image and transform it.\n",
    "         \n",
    "        \"\"\"\n",
    "        \n",
    "        # get label to species mapping\n",
    "        label_csv_path = os.path.join(data_root, 'train.csv')\n",
    "        self.data_df = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n",
    "        self.classes = self.data_df.iloc[:, 1].unique()\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.image_ids = self.data_df.iloc[:, 0]\n",
    "\n",
    "        self.class_given_label = {image_id : image_class for image_id, image_class in enumerate(self.classes)}\n",
    "        self.label_given_class = {image_class : image_id for image_id, image_class in enumerate(self.classes)}\n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "                \n",
    "        else:\n",
    "            self.image_shape = image_shape\n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "\n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "            'label': []\n",
    "        }\n",
    "        img_dir = os.path.join(data_root, 'images', 'images')\n",
    "\n",
    "        # print(\"self.data_df\", type(self.data_df))\n",
    "        for data in self.data_df.iterrows():\n",
    "            image_id = str(data[1]['id']) + '.jpg'\n",
    "            image_path = os.path.join(img_dir, image_id)\n",
    "            image_class = data[1]['class']\n",
    "            label = self.label_given_class[image_class]\n",
    "            self.data_dict['image_path'].append(image_path)\n",
    "            self.data_dict['label'].append(label)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['label'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        image = Image.open(self.data_dict['image_path'][idx]).convert(\"RGB\")\n",
    "        \n",
    "        if self.image_shape is not None:\n",
    "            image = F.resize(image, self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        target = self.data_dict['label'][idx]\n",
    "        \n",
    "        return image, target            \n",
    "                \n",
    "        \n",
    "    def class_name(self, label):\n",
    "        \"\"\"\n",
    "        class label to common name mapping\n",
    "        \"\"\"\n",
    "        return self.class_given_label[label]\n",
    "\n",
    "    def get_classes(self):\n",
    "        return self.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TransformedSubset(Dataset):\n",
    "    def __init__(self, subset, transform):\n",
    "        self.subset = subset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.subset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.subset[idx]  # Get item from subset\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformation\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_std(dataset, batch_size=8, num_workers=4):\n",
    "    \n",
    "    # transform = image_preprocess_transforms()\n",
    "    \n",
    "    # loader = data_loader(data_root, transform)\n",
    "    loader = torch.utils.data.DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    batch_mean = torch.zeros(3)\n",
    "    batch_mean_sqrd = torch.zeros(3)\n",
    "\n",
    "    for batch_data, _ in loader:\n",
    "        batch_mean += batch_data.mean(dim=(0, 2, 3)) # E[batch_i] \n",
    "        batch_mean_sqrd += (batch_data ** 2).mean(dim=(0, 2, 3)) #  E[batch_i**2]\n",
    "    \n",
    "    # E[dataset] = E[E[batch_1], E[batch_2], ...]\n",
    "    mean = batch_mean / len(loader)\n",
    "    \n",
    "    # var[X] = E[X**2] - E[X]**2\n",
    "    \n",
    "    # E[X**2] = E[E[batch_1**2], E[batch_2**2], ...]\n",
    "    # E[X]**2 = E[E[batch_1], E[batch_2], ...] ** 2\n",
    "    \n",
    "    var = (batch_mean_sqrd / len(loader)) - (mean ** 2)\n",
    "        \n",
    "    std = var ** 0.5\n",
    "    print('mean: {}, std: {}'.format(mean, std))\n",
    "    \n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root='data', num_workers=1):\n",
    "    compulsary_preprocess = transforms.Compose([\n",
    "        # Resize to 32X32\n",
    "        # transforms.Resize((32, 32)),\n",
    "        # this re-scale image tensor values between 0-1. image_tensor /= 255\n",
    "        # transforms.ToTensor(),\n",
    "        # subtract mean (0.1307) and divide by variance (0.3081).\n",
    "        # This mean and variance is calculated on training data (verify yourself)\n",
    "        # transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset =  KenyanFood13Dataset(data_root, image_shape=None, transform=compulsary_preprocess)\n",
    "    classes = dataset.get_classes()\n",
    "    \n",
    "    train_size = int(0.8 * len(dataset)) # 80% for training\n",
    "    test_size = len(dataset) - train_size # 20% for validation\n",
    "\n",
    "    train_dataset_compulsary_prepocess, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    train_mean, train_std = get_mean_std(train_dataset_compulsary_prepocess, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "    train_preprocess = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        # transforms.RandomRotation(20),\n",
    "        transforms.ToTensor(),\n",
    "        # transforms.RandomHorizontalFlip(),\n",
    "        # transforms.RandomVerticalFlip(),\n",
    "        # transforms.RandomCrop(28, padding=4),\n",
    "        # transforms.PILToTensor(),\n",
    "        # transforms.ConvertImageDtype(torch.float),\n",
    "        # transforms.RandomPerspective(distortion_scale=0.6, p=1),\n",
    "        # transforms.ColorJitter(brightness=.5, hue=.3),\n",
    "        # transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        transforms.Normalize(mean=train_mean, std=train_std)\n",
    "    ])\n",
    "\n",
    "    # Apply transformation to the subset\n",
    "    train_dataset_subset = TransformedSubset(train_dataset_compulsary_prepocess, train_preprocess)\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset_subset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    return train_loader, test_loader, train_mean, train_std, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PlotLoader(loader):\n",
    "    # Plot few images\n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 9)\n",
    "    plt.figure\n",
    "    for images, labels in loader:\n",
    "        for i in range(len(labels)):\n",
    "            plt.subplot(3, 5, i+1)\n",
    "            img = Fn.to_pil_image(images[i])\n",
    "            plt.imshow(img)\n",
    "            plt.gca().set_title('Target: {0}'.format(labels[i]))\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, test_loader, train_mean, train_std, classes = get_data(batch_size=15, data_root='../../../../data/Week7_project2_classification/KenyanFood13Dataset', num_workers=1)\n",
    "# print(classes)\n",
    "# PlotLoader(train_loader)\n",
    "# print(\"---------\")\n",
    "# PlotLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">2. Define the Model</font>\n",
    "\n",
    "Define the model (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# class LeNet5(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self._body = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#         )\n",
    "#         self._head = nn.Sequential(\n",
    "#             nn.Linear(in_features=16 * 5 * 5, out_features=120), nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=120, out_features=84), nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=84, out_features=10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self._body(x)\n",
    "#         x = x.view(x.size()[0], -1)\n",
    "#         x = self._head(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Linear(in_features=64*52*52, out_features=1024), \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(in_features=1024, out_features=13)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">3. Start Experiment / Training</font>\n",
    "\n",
    "\n",
    "Define the experiment with the given model and given data. It's the same idea again: we keep the less-likely-to-change things inside the object and configure it with the things that are more likely to change.\n",
    "\n",
    "You may wonder, why do we put the specific metric and optimizer into the experiment code and not specify them as parameters. But the experiment class is just a handy way to store all the parts of your experiment in one place. If you change the loss function, or the optimizer, or the model - it seems like another experiment, right? So it deserves to be a separate class.\n",
    "\n",
    "The Trainer class inner structure is a bit more complicated compared to what we've discussed above - it is just to be able to cope with the different kinds of the tasks we will discuss in this course. We will elaborate a bit more on the Trainer inner structure in the following lectures and now take a look at how compact and self-descriptive the code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n",
    "        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),\n",
    "        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n",
    "        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig()\n",
    "    ):\n",
    "        self.loader_train, self.loader_test, self.train_mean, self.train_std, self.labels = get_data(\n",
    "            batch_size=dataloader_config.batch_size,\n",
    "            num_workers=dataloader_config.num_workers,\n",
    "            data_root=dataset_config.root_dir\n",
    "        )\n",
    "        \n",
    "        setup_system(system_config)\n",
    "\n",
    "        self.model = LeNet5()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.metric_fn = AccuracyEstimator(topk=(1, ))\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=optimizer_config.learning_rate,\n",
    "            weight_decay=optimizer_config.weight_decay,\n",
    "            momentum=optimizer_config.momentum\n",
    "        )\n",
    "        self.lr_scheduler = MultiStepLR(\n",
    "            self.optimizer, milestones=optimizer_config.lr_step_milestones, gamma=optimizer_config.lr_gamma\n",
    "        )\n",
    "        self.visualizer = TensorBoardVisualizer()\n",
    "\n",
    "    def run(self, trainer_config: configuration.TrainerConfig) -> dict:\n",
    "\n",
    "        device = torch.device(trainer_config.device)\n",
    "        self.model = self.model.to(device)\n",
    "        self.loss_fn = self.loss_fn.to(device)\n",
    "\n",
    "        model_trainer = Trainer(\n",
    "            model=self.model,\n",
    "            loader_train=self.loader_train,\n",
    "            loader_test=self.loader_test,\n",
    "            loss_fn=self.loss_fn,\n",
    "            metric_fn=self.metric_fn,\n",
    "            optimizer=self.optimizer,\n",
    "            lr_scheduler=self.lr_scheduler,\n",
    "            device=device,\n",
    "            data_getter=itemgetter(0),\n",
    "            target_getter=itemgetter(1),\n",
    "            stage_progress=trainer_config.progress_bar,\n",
    "            get_key_metric=itemgetter(\"top1\"),\n",
    "            visualizer=self.visualizer,\n",
    "            model_saving_frequency=trainer_config.model_saving_frequency,\n",
    "            save_dir=trainer_config.model_dir\n",
    "        )\n",
    "        \n",
    "        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n",
    "        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n",
    "        return self.metrics, self.train_mean, self.train_std, self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''Run the experiment\n",
    "    '''\n",
    "    # patch configs depending on cuda availability\n",
    "    dataloader_config, trainer_config = patch_configs(epoch_num_to_set=1)#5)\n",
    "    # dataset_config = configuration.DatasetConfig(root_dir=\"data\")\n",
    "    dataset_config = configuration.DatasetConfig(root_dir=\"../../../../data/Week7_project2_classification/KenyanFood13Dataset\")\n",
    "    experiment = Experiment(dataset_config=dataset_config, dataloader_config=dataloader_config)\n",
    "    results, train_mean, train_std, labels = experiment.run(trainer_config)\n",
    "\n",
    "    return results, train_mean, train_std, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ == '__main__':\n",
    "#     results, train_mean, train_std, labels = main()\n",
    "#     print(train_mean, train_std, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Predictions</font><a name=\"predictions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Make Predictions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Get Predictions on a Batch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KenyanFood13DatasetTest(Dataset):\n",
    "    \"\"\"\n",
    "    This custom dataset class takes root directory and train flag, \n",
    "    and returns dataset training dataset if train flag is true \n",
    "    else it returns validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, image_shape=None, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        init method of the class.\n",
    "        \n",
    "         Parameters:\n",
    "         \n",
    "         data_root (string): path of root directory.\n",
    "         \n",
    "         train (boolean): True for training dataset and False for test dataset.\n",
    "         \n",
    "         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n",
    "                                             If it is not None image will resize to the given shape.\n",
    "                                 \n",
    "         transform (method): method that will take PIL image and transform it.\n",
    "         \n",
    "        \"\"\"\n",
    "        \n",
    "        # get label to species mapping\n",
    "        label_csv_path = os.path.join(data_root, 'test.csv')\n",
    "        # label_csv_path = os.path.join(data_root, 'test_trial1.csv')\n",
    "        self.data_df = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n",
    "        self.image_ids = self.data_df.iloc[:, 0]\n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "                \n",
    "        else:\n",
    "            self.image_shape = image_shape\n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "\n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "        }\n",
    "        img_dir = os.path.join(data_root, 'images', 'images')\n",
    "\n",
    "        for data in self.data_df.iterrows():\n",
    "            image_id = str(data[1]['id']) + '.jpg'\n",
    "            image_path = os.path.join(img_dir, image_id)\n",
    "            self.data_dict['image_path'].append(image_path)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['image_path'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        image = Image.open(self.data_dict['image_path'][idx]).convert(\"RGB\")\n",
    "        \n",
    "        if self.image_shape is not None:\n",
    "            image = Fn.resize(image, self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, self.image_ids.iat[idx]\n",
    "    \n",
    "    # def get_image_id(self, idx):\n",
    "    #     return self.image_ids.iat[idx]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '../../../../data/Week7_project2_classification/KenyanFood13Dataset'\n",
    "\n",
    "# dataset =  KenyanFood13DatasetTest(data_root, image_shape=256)\n",
    "\n",
    "# # print('Length of the dataset: {}'.format(len(dataset)))\n",
    "\n",
    "# img, img_id = dataset[5]\n",
    "# print(img.size)\n",
    "# print('Image_id: {}'.format(img_id))\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir, model_file_name):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    return model, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input):\n",
    "    \n",
    "#     data = batch_input.to(device)\n",
    "    data = batch_input.to(\"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">Compulsary Preprocessing Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compulsary_transforms():\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">Common Image Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_compulsary_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_prediction(model, data_root, train_mean, train_std, labels, output_root):\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "    \n",
    "    \n",
    "    test_dataset_trans =  KenyanFood13DatasetTest(data_root, image_shape=None, transform=image_common_transforms(train_mean, train_std))\n",
    "    \n",
    "    batch_size = 15\n",
    "    num_workers = 4\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # test_loader_trans = torch.utils.data.DataLoader(\n",
    "    #     test_dataset_trans,\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=False,\n",
    "    #     num_workers=num_workers\n",
    "    # )\n",
    "\n",
    "    # PlotLoader(test_loader)\n",
    "    # print(\"----------------\")\n",
    "    # PlotLoader(test_loader_trans)\n",
    "    \n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        num_workers = 8\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers = 2\n",
    "    \n",
    "    # It is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "    \n",
    "    # Send model to cpu/cuda according to your system configuration\n",
    "#     model.to(device)\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    data_len = test_dataset_trans.__len__()\n",
    "    print(\"data_len: \", data_len)\n",
    "    \n",
    "    interval = 1 #int(data_len/batch_size)\n",
    "    classes = []\n",
    "    image_ids = []\n",
    "    for start in range(0, data_len, batch_size):\n",
    "        # end_ = (data_len - start) % batch_size\n",
    "        end = start + batch_size\n",
    "        end = min(end, data_len)\n",
    "        # print('start: {}, end: {}'.format(start, end))\n",
    "\n",
    "        trans_images = []\n",
    "        for index in range(start, end):\n",
    "            trans_image, image_id = test_dataset_trans[index]\n",
    "            # print('index: {}, img_id: {}'.format(index, img_id))\n",
    "    \n",
    "            trans_images.append(trans_image)\n",
    "            image_ids.append(image_id)\n",
    "        \n",
    "        trans_images = torch.stack(trans_images)\n",
    "        classes_index, prob = prediction(model, device, batch_input=trans_images)\n",
    "        # print(\"classes_index:\", classes_index)\n",
    "        \n",
    "        classes.extend([labels[class_index] for class_index in classes_index])\n",
    "    \n",
    "    data = {\n",
    "        'id': image_ids,\n",
    "        'class': classes\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    label_csv_path = os.path.join(output_root, 'output.csv')\n",
    "    df.to_csv(label_csv_path, sep=\",\", index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Load Model and Run Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2.5089458285308464\n"
     ]
    }
   ],
   "source": [
    "m = LeNet5()\n",
    "model_dir = \"./checkpoints\"\n",
    "model_file_name = \"checkpoint1.pt\"\n",
    "model, epoch, loss = load_model(m, model_dir, model_file_name)\n",
    "print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_len:  1638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/virtualenvs/pytorch_env/lib/python3.12/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /pytorch/c10/cuda/CUDAFunctions.cpp:109.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "train_mean=torch.tensor([0.5772715211, 0.4631873667, 0.3466044068])\n",
    "train_std =torch.tensor([0.2699360847, 0.2737641633, 0.2830057442])\n",
    "labels = ['githeri', 'ugali', 'kachumbari', 'matoke', 'sukumawiki', 'bhaji', 'mandazi',\n",
    " 'kukuchoma', 'nyamachoma', 'pilau', 'chapati', 'masalachips', 'mukimo']\n",
    "get_sample_prediction(model, data_root, train_mean, train_std, labels, \"./submissions/\")\n",
    "\n",
    "# PlotLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a few lines of code, we got a more robust system that we had before - we have richer visualizations, a more configurable training process, and we separated the pipeline for the training from the model - so we can concentrate on the things that matter the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "You may wonder whether it is a common way of doing deep learning or we're doing overengineering here. We may assure you that this is a common way to do deep learning research in an industry - most of the companies and research groups invest in building these DL training frameworks for their projects, and some of them are even published to the open-source. To name a couple of them:\n",
    "- https://github.com/NVlabs/SPADE\n",
    "- https://github.com/pytorch/ignite\n",
    "- https://github.com/PyTorchLightning/pytorch-lightning\n",
    "- https://github.com/catalyst-team/catalyst\n",
    "- https://github.com/open-mmlab/mmdetection\n",
    "- https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
