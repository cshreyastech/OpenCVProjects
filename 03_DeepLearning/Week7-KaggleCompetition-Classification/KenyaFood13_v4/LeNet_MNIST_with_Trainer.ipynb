{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Combine them all: LeNet5 pipeline with Trainer</font>\n",
    "\n",
    "Let's take a look at how we can build the training pipeline using the Trainer helper class and the other helper classes we've discussed before in this notebook.\n",
    "Import all the necessary classes and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shreyas/virtualenvs/pytorch_env/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'trainer.configuration'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 19\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# from torchvision import datasets, transforms\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m MultiStepLR\n\u001b[0;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer, hooks, configuration\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KenyanFood13Dataset, TransformedSubset\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtest_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KenyanFood13DatasetTest\n",
      "File \u001b[0;32m/mnt/localcodebase/OpenCVProjects/03_DeepLearning/Week7-KaggleCompetition-Classification/KenyaFood13_v4/trainer/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Trainer\n",
      "File \u001b[0;32m/mnt/localcodebase/OpenCVProjects/03_DeepLearning/Week7-KaggleCompetition-Classification/KenyaFood13_v4/trainer/trainer.py:25\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ReduceLROnPlateau\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhooks\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m test_hook_default, train_hook_default\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvisualizer\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Visualizer\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# ## <font style=\"color:blue\">Trainer Class Methods and its Parameters</font>\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# ### <font style=\"color:green\">  \\_\\_init\\_\\_ </font>\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;66;03m# - `epochs`: `int` - number of epochs to train model.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/localcodebase/OpenCVProjects/03_DeepLearning/Week7-KaggleCompetition-Classification/KenyaFood13_v4/trainer/hooks.py:23\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mauto\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AverageMeter\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# ## <font style=\"color:green\">train_hook_default</font>\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Default train loop function for single epoch. \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;66;03m# - `stage_progress` (`bool`): if True then progress bar will be show.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mtrain_hook_default\u001b[39m(\n\u001b[1;32m     63\u001b[0m     model,\n\u001b[1;32m     64\u001b[0m     loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     72\u001b[0m     stage_progress\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     73\u001b[0m ):\n",
      "File \u001b[0;32m/mnt/localcodebase/OpenCVProjects/03_DeepLearning/Week7-KaggleCompetition-Classification/KenyaFood13_v4/trainer/utils.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconfiguration\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SystemConfig, TrainerConfig, DataloaderConfig\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# ## <font style=\"color:green\">AverageMeter</font>\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Computes and stores the average and current value.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mAverageMeter\u001b[39;00m:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trainer.configuration'"
     ]
    }
   ],
   "source": [
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as Fn\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from trainer import Trainer, hooks, configuration\n",
    "\n",
    "from trainer.trainer_dataset import KenyanFood13Dataset, TransformedSubset\n",
    "from trainer.test_dataset import KenyanFood13DatasetTest\n",
    "\n",
    "from trainer.experinment_utils import get_mean_std, get_data\n",
    "from trainer.configuration import Model\n",
    "from trainer.utils import setup_system, patch_configs\n",
    "from trainer.metrics import AccuracyEstimator\n",
    "from trainer.tensorboard_visualizer import TensorBoardVisualizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "from PIL import Image\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">1. Get Training and Validation Data Loader</font>\n",
    "\n",
    "\n",
    "Define the data wrappers and transformations (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def PlotLoader(loader):\n",
    "#     # Plot few images\n",
    "#     plt.rcParams[\"figure.figsize\"] = (15, 9)\n",
    "#     plt.figure\n",
    "#     for images, labels in loader:\n",
    "#         for i in range(len(labels)):\n",
    "#             plt.subplot(3, 5, i+1)\n",
    "#             img = Fn.to_pil_image(images[i])\n",
    "#             plt.imshow(img)\n",
    "#             plt.gca().set_title('Target: {0}'.format(labels[i]))\n",
    "#         plt.show()\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loader, test_loader, train_mean, train_std, classes = get_data(batch_size=15, data_root='../../../../data/Week7_project2_classification/KenyanFood13Dataset', num_workers=1)\n",
    "# print(classes)\n",
    "# PlotLoader(train_loader)\n",
    "# print(\"---------\")\n",
    "# PlotLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">2. Define the Model</font>\n",
    "\n",
    "Define the model (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">3. Start Experiment / Training</font>\n",
    "\n",
    "\n",
    "Define the experiment with the given model and given data. It's the same idea again: we keep the less-likely-to-change things inside the object and configure it with the things that are more likely to change.\n",
    "\n",
    "You may wonder, why do we put the specific metric and optimizer into the experiment code and not specify them as parameters. But the experiment class is just a handy way to store all the parts of your experiment in one place. If you change the loss function, or the optimizer, or the model - it seems like another experiment, right? So it deserves to be a separate class.\n",
    "\n",
    "The Trainer class inner structure is a bit more complicated compared to what we've discussed above - it is just to be able to cope with the different kinds of the tasks we will discuss in this course. We will elaborate a bit more on the Trainer inner structure in the following lectures and now take a look at how compact and self-descriptive the code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n",
    "        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),\n",
    "        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n",
    "        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig(),\n",
    "        trainer_config: configuration.TrainerConfig = configuration.TrainerConfig()\n",
    "    ):\n",
    "        self.loader_train, self.loader_test, self.train_mean, self.train_std, self.labels = get_data(\n",
    "            batch_size=dataloader_config.batch_size,\n",
    "            num_workers=dataloader_config.num_workers,\n",
    "            data_root=dataset_config.root_dir\n",
    "        )\n",
    "        \n",
    "        setup_system(system_config)\n",
    "\n",
    "        self.model = Model1()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.metric_fn = AccuracyEstimator(topk=(1, ))\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=optimizer_config.learning_rate,\n",
    "            weight_decay=optimizer_config.weight_decay,\n",
    "            momentum=optimizer_config.momentum\n",
    "        )\n",
    "        self.lr_scheduler = MultiStepLR(\n",
    "            self.optimizer, milestones=optimizer_config.lr_step_milestones, gamma=optimizer_config.lr_gamma\n",
    "        )\n",
    "        self.visualizer = TensorBoardVisualizer(trainer_config.tensor_board_dir)\n",
    "\n",
    "    def run(self, trainer_config: configuration.TrainerConfig) -> dict:\n",
    "\n",
    "        device = torch.device(trainer_config.device)\n",
    "        self.model = self.model.to(device)\n",
    "        self.loss_fn = self.loss_fn.to(device)\n",
    "\n",
    "        model_trainer = Trainer(\n",
    "            model=self.model,\n",
    "            loader_train=self.loader_train,\n",
    "            loader_test=self.loader_test,\n",
    "            loss_fn=self.loss_fn,\n",
    "            metric_fn=self.metric_fn,\n",
    "            optimizer=self.optimizer,\n",
    "            lr_scheduler=self.lr_scheduler,\n",
    "            device=device,\n",
    "            data_getter=itemgetter(0),\n",
    "            target_getter=itemgetter(1),\n",
    "            stage_progress=trainer_config.progress_bar,\n",
    "            get_key_metric=itemgetter(\"top1\"),\n",
    "            visualizer=self.visualizer,\n",
    "            model_saving_frequency=trainer_config.model_saving_frequency,\n",
    "            save_dir=trainer_config.model_dir,\n",
    "            model_name_prefix=trainer_config.trainer_name\n",
    "        )\n",
    "        \n",
    "        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n",
    "        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n",
    "        return self.metrics, self.train_mean, self.train_std, self.labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''Run the experiment\n",
    "    '''\n",
    "    # patch configs depending on cuda availability\n",
    "    dataloader_config, trainer_config = patch_configs(epoch_num_to_set=5)\n",
    "    dataset_config = configuration.DatasetConfig()\n",
    "    experiment = Experiment(dataset_config=dataset_config, dataloader_config=dataloader_config)\n",
    "    results, train_mean, train_std, labels = experiment.run(trainer_config)\n",
    "\n",
    "    return results, train_mean, train_std, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    results, train_mean, train_std, labels = main()\n",
    "    # print(train_mean, train_std, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Predictions</font><a name=\"predictions\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Make Predictions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Get Predictions on a Batch</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = configuration.DatasetConfig()\n",
    "data_root = dataset_config.root_dir #'../../../../data/Week7_project2_classification/KenyanFood13Dataset'\n",
    "\n",
    "# dataset =  KenyanFood13DatasetTest(data_root, image_shape=256)\n",
    "\n",
    "# # print('Length of the dataset: {}'.format(len(dataset)))\n",
    "\n",
    "# img, img_id = dataset[5]\n",
    "# print(img.size)\n",
    "# print('Image_id: {}'.format(img_id))\n",
    "# plt.imshow(img)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, model_dir, model_file_name):\n",
    "    model_path = os.path.join(model_dir, model_file_name)\n",
    "\n",
    "    # loading the model and getting model parameters by using load_state_dict\n",
    "    checkpoint = torch.load(model_path)\n",
    "    \n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "\n",
    "    return model, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, device, batch_input):\n",
    "    \n",
    "#     data = batch_input.to(device)\n",
    "    data = batch_input.to(\"cpu\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model(data)\n",
    "\n",
    "    # Score to probability using softmax\n",
    "    prob = F.softmax(output, dim=1)\n",
    "\n",
    "    # get the max probability\n",
    "    pred_prob = prob.data.max(dim=1)[0]\n",
    "    \n",
    "    # get the index of the max probability\n",
    "    pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">Compulsary Preprocessing Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_compulsary_transforms():\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font style=\"color:green\">Common Image Transforms</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_common_transforms(mean=(0.4611, 0.4359, 0.3905), std=(0.2193, 0.2150, 0.2109)):\n",
    "    preprocess = image_compulsary_transforms()\n",
    "    \n",
    "    common_transforms = transforms.Compose([\n",
    "        preprocess,\n",
    "        transforms.Normalize(mean, std)\n",
    "    ])\n",
    "    \n",
    "    return common_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_prediction(model, data_root, train_mean, train_std, labels, output_root):\n",
    "    transforms.Normalize(train_mean, train_std)\n",
    "    \n",
    "    \n",
    "    test_dataset_trans =  KenyanFood13DatasetTest(data_root, image_shape=None, transform=image_common_transforms(train_mean, train_std))\n",
    "    \n",
    "    batch_size = 15\n",
    "    num_workers = 4\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "        num_workers = 8\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        num_workers = 2\n",
    "    \n",
    "    # It is important to do model.eval() before prediction\n",
    "    model.eval()\n",
    "    \n",
    "    # Send model to cpu/cuda according to your system configuration\n",
    "#     model.to(device)\n",
    "    model.to(\"cpu\")\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    data_len = test_dataset_trans.__len__()\n",
    "    print(\"data_len: \", data_len)\n",
    "    \n",
    "    interval = 1 #int(data_len/batch_size)\n",
    "    classes = []\n",
    "    image_ids = []\n",
    "    for start in range(0, data_len, batch_size):\n",
    "        end = start + batch_size\n",
    "        end = min(end, data_len)\n",
    "        # print('start: {}, end: {}'.format(start, end))\n",
    "\n",
    "        trans_images = []\n",
    "        for index in range(start, end):\n",
    "            trans_image, image_id = test_dataset_trans[index]\n",
    "            # print('index: {}, img_id: {}'.format(index, img_id))\n",
    "    \n",
    "            trans_images.append(trans_image)\n",
    "            image_ids.append(image_id)\n",
    "        \n",
    "        trans_images = torch.stack(trans_images)\n",
    "        classes_index, prob = prediction(model, device, batch_input=trans_images)\n",
    "        # print(\"classes_index:\", classes_index)\n",
    "        \n",
    "        classes.extend([labels[class_index] for class_index in classes_index])\n",
    "    \n",
    "    data = {\n",
    "        'id': image_ids,\n",
    "        'class': classes\n",
    "    }\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    label_csv_path = os.path.join(output_root, 'output.csv')\n",
    "    df.to_csv(label_csv_path, sep=\",\", index=False)\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Load Model and Run Inference</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m = LeNet5()\n",
    "# model_dir = \"./checkpoints\"\n",
    "# model_file_name = \"checkpoint1.pt\"\n",
    "# model, epoch, loss = load_model(m, model_dir, model_file_name)\n",
    "# print(epoch, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_mean=torch.tensor([0.5772715211, 0.4631873667, 0.3466044068])\n",
    "# train_std =torch.tensor([0.2699360847, 0.2737641633, 0.2830057442])\n",
    "# labels = ['githeri', 'ugali', 'kachumbari', 'matoke', 'sukumawiki', 'bhaji', 'mandazi',\n",
    "#  'kukuchoma', 'nyamachoma', 'pilau', 'chapati', 'masalachips', 'mukimo']\n",
    "# get_sample_prediction(model, data_root, train_mean, train_std, labels, \"./submissions/\")\n",
    "\n",
    "# # PlotLoader(test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a few lines of code, we got a more robust system that we had before - we have richer visualizations, a more configurable training process, and we separated the pipeline for the training from the model - so we can concentrate on the things that matter the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "You may wonder whether it is a common way of doing deep learning or we're doing overengineering here. We may assure you that this is a common way to do deep learning research in an industry - most of the companies and research groups invest in building these DL training frameworks for their projects, and some of them are even published to the open-source. To name a couple of them:\n",
    "- https://github.com/NVlabs/SPADE\n",
    "- https://github.com/pytorch/ignite\n",
    "- https://github.com/PyTorchLightning/pytorch-lightning\n",
    "- https://github.com/catalyst-team/catalyst\n",
    "- https://github.com/open-mmlab/mmdetection\n",
    "- https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
