{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Combine them all: LeNet5 pipeline with Trainer</font>\n",
    "\n",
    "Let's take a look at how we can build the training pipeline using the Trainer helper class and the other helper classes we've discussed before in this notebook.\n",
    "Import all the necessary classes and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "\n",
    "from trainer import Trainer, hooks, configuration\n",
    "from trainer.utils import setup_system, patch_configs\n",
    "from trainer.metrics import AccuracyEstimator\n",
    "from trainer.tensorboard_visualizer import TensorBoardVisualizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "# from typing import Iterable\n",
    "# from dataclasses import dataclass\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">1. Get Training and Validation Data Loader</font>\n",
    "\n",
    "\n",
    "Define the data wrappers and transformations (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KenyanFood13Dataset(Dataset):\n",
    "    \"\"\"\n",
    "    This custom dataset class takes root directory and train flag, \n",
    "    and returns dataset training dataset if train flag is true \n",
    "    else it returns validation dataset.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_root, image_shape=None, transform=None):\n",
    "        \n",
    "        \"\"\"\n",
    "        init method of the class.\n",
    "        \n",
    "         Parameters:\n",
    "         \n",
    "         data_root (string): path of root directory.\n",
    "         \n",
    "         train (boolean): True for training dataset and False for test dataset.\n",
    "         \n",
    "         image_shape (int or tuple or list): [optional] int or tuple or list. Defaut is None. \n",
    "                                             If it is not None image will resize to the given shape.\n",
    "                                 \n",
    "         transform (method): method that will take PIL image and transform it.\n",
    "         \n",
    "        \"\"\"\n",
    "        \n",
    "        # get label to species mapping\n",
    "        label_csv_path = os.path.join(data_root, 'train.csv')\n",
    "        self.data_df = pd.read_csv(label_csv_path, delimiter=' *, *', engine='python')\n",
    "        self.classes = self.data_df.iloc[:, 1].unique()\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.image_ids = self.data_df.iloc[:, 0]\n",
    "\n",
    "        self.class_given_label = {image_id : image_class for image_id, image_class in enumerate(self.classes)}\n",
    "        self.label_given_class = {image_class : image_id for image_id, image_class in enumerate(self.classes)}\n",
    "        \n",
    "        # set image_resize attribute\n",
    "        if image_shape is not None:\n",
    "            if isinstance(image_shape, int):\n",
    "                self.image_shape = (image_shape, image_shape)\n",
    "            \n",
    "            elif isinstance(image_shape, tuple) or isinstance(image_shape, list):\n",
    "                assert len(image_shape) == 1 or len(image_shape) == 2, 'Invalid image_shape tuple size'\n",
    "                if len(image_shape) == 1:\n",
    "                    self.image_shape = (image_shape[0], image_shape[0])\n",
    "                else:\n",
    "                    self.image_shape = image_shape\n",
    "            else:\n",
    "                raise NotImplementedError \n",
    "                \n",
    "        else:\n",
    "            self.image_shape = image_shape\n",
    "            \n",
    "        # set transform attribute\n",
    "        self.transform = transform\n",
    "\n",
    "        # initialize the data dictionary\n",
    "        self.data_dict = {\n",
    "            'image_path': [],\n",
    "            'label': []\n",
    "        }\n",
    "        img_dir = os.path.join(data_root, 'images', 'images')\n",
    "\n",
    "        # print(\"self.data_df\", type(self.data_df))\n",
    "        for data in self.data_df.iterrows():\n",
    "            image_id = str(data[1]['id']) + '.jpg'\n",
    "            image_path = os.path.join(img_dir, image_id)\n",
    "            image_class = data[1]['class']\n",
    "            label = self.label_given_class[image_class]\n",
    "            self.data_dict['image_path'].append(image_path)\n",
    "            self.data_dict['label'].append(label)\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        return length of the dataset\n",
    "        \"\"\"\n",
    "        return len(self.data_dict['label'])\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        For given index, return images with resize and preprocessing.\n",
    "        \"\"\"\n",
    "        \n",
    "        image = Image.open(self.data_dict['image_path'][idx]).convert(\"RGB\")\n",
    "        \n",
    "        if self.image_shape is not None:\n",
    "            image = F.resize(image, self.image_shape)\n",
    "            \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        target = self.data_dict['label'][idx]\n",
    "        \n",
    "        return image, target            \n",
    "                \n",
    "        \n",
    "    def class_name(self, label):\n",
    "        \"\"\"\n",
    "        class label to common name mapping\n",
    "        \"\"\"\n",
    "        return self.class_given_label[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root='data', num_workers=1):\n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # Resize to 32X32\n",
    "        # transforms.Resize((32, 32)),\n",
    "        # this re-scale image tensor values between 0-1. image_tensor /= 255\n",
    "        # transforms.ToTensor(),\n",
    "        # subtract mean (0.1307) and divide by variance (0.3081).\n",
    "        # This mean and variance is calculated on training data (verify yourself)\n",
    "        # transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset =  KenyanFood13Dataset(data_root, image_shape=None, transform=train_test_transforms)\n",
    "\n",
    "    train_size = int(0.8 * len(dataset)) # 80% for training\n",
    "    test_size = len(dataset) - train_size # 20% for validation\n",
    "\n",
    "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    # dataloader with dataset\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "    # # train dataloader\n",
    "    # train_loader = torch.utils.data.DataLoader(\n",
    "    #     datasets.MNIST(root=data_root, train=True, download=True, transform=train_test_transforms),\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=True,\n",
    "    #     num_workers=num_workers\n",
    "    # )\n",
    "\n",
    "    # # test dataloader\n",
    "    # test_loader = torch.utils.data.DataLoader(\n",
    "    #     datasets.MNIST(root=data_root, train=False, download=True, transform=train_test_transforms),\n",
    "    #     batch_size=batch_size,\n",
    "    #     shuffle=False,\n",
    "    #     num_workers=num_workers\n",
    "    # )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data(batch_size=15, data_root='../../../../data/Week7_project2_classification/KenyanFood13Dataset', num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot few images\n",
    "plt.rcParams[\"figure.figsize\"] = (15, 9)\n",
    "plt.figure\n",
    "for images, labels in test_loader:\n",
    "    for i in range(len(labels)):\n",
    "        plt.subplot(3, 5, i+1)\n",
    "        img = F.to_pil_image(images[i])\n",
    "        plt.imshow(img)\n",
    "        plt.gca().set_title('Target: {0}'.format(labels[i]))\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">2. Define the Model</font>\n",
    "\n",
    "Define the model (the same way as before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# class LeNet5(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super().__init__()\n",
    "\n",
    "#         self._body = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#             nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "#             nn.ReLU(inplace=True),\n",
    "#             nn.MaxPool2d(kernel_size=2),\n",
    "#         )\n",
    "#         self._head = nn.Sequential(\n",
    "#             nn.Linear(in_features=16 * 5 * 5, out_features=120), nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=120, out_features=84), nn.ReLU(inplace=True),\n",
    "#             nn.Linear(in_features=84, out_features=10)\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self._body(x)\n",
    "#         x = x.view(x.size()[0], -1)\n",
    "#         x = self._head(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=7),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            nn.Linear(in_features=64*52*52, out_features=1024), \n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(in_features=1024, out_features=13)\n",
    "            \n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:Green\">3. Start Experiment / Training</font>\n",
    "\n",
    "\n",
    "Define the experiment with the given model and given data. It's the same idea again: we keep the less-likely-to-change things inside the object and configure it with the things that are more likely to change.\n",
    "\n",
    "You may wonder, why do we put the specific metric and optimizer into the experiment code and not specify them as parameters. But the experiment class is just a handy way to store all the parts of your experiment in one place. If you change the loss function, or the optimizer, or the model - it seems like another experiment, right? So it deserves to be a separate class.\n",
    "\n",
    "The Trainer class inner structure is a bit more complicated compared to what we've discussed above - it is just to be able to cope with the different kinds of the tasks we will discuss in this course. We will elaborate a bit more on the Trainer inner structure in the following lectures and now take a look at how compact and self-descriptive the code is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    def __init__(\n",
    "        self,\n",
    "        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n",
    "        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),\n",
    "        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n",
    "        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig()\n",
    "    ):\n",
    "        self.loader_train, self.loader_test = get_data(\n",
    "            batch_size=dataloader_config.batch_size,\n",
    "            num_workers=dataloader_config.num_workers,\n",
    "            data_root=dataset_config.root_dir\n",
    "        )\n",
    "        \n",
    "        setup_system(system_config)\n",
    "\n",
    "        self.model = LeNet5()\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.metric_fn = AccuracyEstimator(topk=(1, ))\n",
    "        self.optimizer = optim.SGD(\n",
    "            self.model.parameters(),\n",
    "            lr=optimizer_config.learning_rate,\n",
    "            weight_decay=optimizer_config.weight_decay,\n",
    "            momentum=optimizer_config.momentum\n",
    "        )\n",
    "        self.lr_scheduler = MultiStepLR(\n",
    "            self.optimizer, milestones=optimizer_config.lr_step_milestones, gamma=optimizer_config.lr_gamma\n",
    "        )\n",
    "        self.visualizer = TensorBoardVisualizer()\n",
    "\n",
    "    def run(self, trainer_config: configuration.TrainerConfig) -> dict:\n",
    "\n",
    "        device = torch.device(trainer_config.device)\n",
    "        self.model = self.model.to(device)\n",
    "        self.loss_fn = self.loss_fn.to(device)\n",
    "\n",
    "        model_trainer = Trainer(\n",
    "            model=self.model,\n",
    "            loader_train=self.loader_train,\n",
    "            loader_test=self.loader_test,\n",
    "            loss_fn=self.loss_fn,\n",
    "            metric_fn=self.metric_fn,\n",
    "            optimizer=self.optimizer,\n",
    "            lr_scheduler=self.lr_scheduler,\n",
    "            device=device,\n",
    "            data_getter=itemgetter(0),\n",
    "            target_getter=itemgetter(1),\n",
    "            stage_progress=trainer_config.progress_bar,\n",
    "            get_key_metric=itemgetter(\"top1\"),\n",
    "            visualizer=self.visualizer,\n",
    "            model_saving_frequency=trainer_config.model_saving_frequency,\n",
    "            save_dir=trainer_config.model_dir\n",
    "        )\n",
    "\n",
    "        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_classification)\n",
    "        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n",
    "        return self.metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    '''Run the experiment\n",
    "    '''\n",
    "    # patch configs depending on cuda availability\n",
    "    dataloader_config, trainer_config = patch_configs(epoch_num_to_set=1)#5)\n",
    "    # dataset_config = configuration.DatasetConfig(root_dir=\"data\")\n",
    "    dataset_config = configuration.DatasetConfig(root_dir=\"../../../../data/Week7_project2_classification/KenyanFood13Dataset\")\n",
    "    experiment = Experiment(dataset_config=dataset_config, dataloader_config=dataloader_config)\n",
    "    results = experiment.run(trainer_config)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in a few lines of code, we got a more robust system that we had before - we have richer visualizations, a more configurable training process, and we separated the pipeline for the training from the model - so we can concentrate on the things that matter the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">References</font>\n",
    "\n",
    "You may wonder whether it is a common way of doing deep learning or we're doing overengineering here. We may assure you that this is a common way to do deep learning research in an industry - most of the companies and research groups invest in building these DL training frameworks for their projects, and some of them are even published to the open-source. To name a couple of them:\n",
    "- https://github.com/NVlabs/SPADE\n",
    "- https://github.com/pytorch/ignite\n",
    "- https://github.com/PyTorchLightning/pytorch-lightning\n",
    "- https://github.com/catalyst-team/catalyst\n",
    "- https://github.com/open-mmlab/mmdetection\n",
    "- https://github.com/fastai/fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
