{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Table of contents</font>\n",
    "\n",
    "- [LeNet5 Architecture](#lenet)\n",
    "- [Display the Network](#display)\n",
    "- [Get the Fashion-MNIST Data](#get-data)\n",
    "- [System Configuration](#sys-config)\n",
    "- [Training Configuration](#train-config)\n",
    "- [System Setup](#sys-setup)\n",
    "- [Training](#training)\n",
    "- [Validation](#validation)\n",
    "- [Main function](#main)\n",
    "- [Plot Loss](#plot-loss)\n",
    "- [Miscellaneous](#misc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Convolutional Neural Network Using Batch Normalization</font>\n",
    "\n",
    "In this notebook, we  add batch norm layers to the LeNet network, and see how it affects network training and convergence.\n",
    "\n",
    "Instead of the MNIST dataset, which overfits easily, we will use the Fashion MNIST dataset.\n",
    "\n",
    "The figure below shows some samples from the Fashion MNIST dataset.\n",
    "\n",
    "<img src=\"https://www.learnopencv.com/wp-content/uploads/2021/01/c3-w3-fashion-mnist-sprite.jpg\" width=\"600\">\n",
    "\n",
    "There are 10 classes. Each training and testing example is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n",
    "\n",
    "\n",
    "\n",
    "We want to classify images in this dataset, using the LeNet network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics library for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. LeNet Architecture with BatchNorm</font><a name=\"lenet\"></a>\n",
    "\n",
    "We have already explained the architecture for LeNet in the previous notebook.\n",
    "\n",
    "Here, we create another model called LeNetBN, adding Batch Normalization layers to the 2 convolution blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (28, 28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2-d\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            # input size = (14, 14), output size = (10, 10)\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (5, 5)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120 \n",
    "            nn.Linear(in_features=120, out_features=84), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third fully connected layer which is also output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weight_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNetBN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (28, 28)\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            nn.BatchNorm2d(6),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2-d\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            # input size = (14, 14), output size = (10, 10)\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (5, 5)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weight in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120 \n",
    "            nn.Linear(in_features=120, out_features=84), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third fully connected layer. It is also output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weights_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Display the Network</font><a name=\"display\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "LeNetBN(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): BatchNorm2d(6, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (5): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lenet_model = LeNet()\n",
    "print(lenet_model)\n",
    "lenetBN_model = LeNetBN()\n",
    "print(lenetBN_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:green\">3. Get Fashion-MNIST Data</font><a name=\"get-data\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root='../../../../data/Fasion_MNIST/', num_workers=1):\n",
    "    \n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # Resize to 32X32\n",
    "        transforms.Resize((32, 32)),\n",
    "        # this re-scales image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean (0.2860) and divide by variance (0.3530).\n",
    "        # This mean and variance is calculated on training data (verify for yourself)\n",
    "        transforms.Normalize((0.2860, ), (0.3530, ))\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(root=data_root, train=True, download=True, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(root=data_root, train=False, download=True, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. System Configuration</font><a name=\"sys-config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Training Configuration</font><a name=\"train-config\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 1  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.01  # determines the speed of network's weights update\n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"../../../../data/Fasion_MNIST/\"  # folder to save MNIST data (default: data)\n",
    "    num_workers: int = 10  # number of concurrent processes used to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. System Setup</font><a name=\"sys-setup\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Training</font><a name=\"training\"></a>\n",
    "We are familiar with the training pipeline used in PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> None:\n",
    "    \n",
    "    # change model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (its is medatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. Validation</font><a name=\"validation\"></a>\n",
    "\n",
    "After every few epochs **`validation`** is called, with the `trained model` and `test_loader` to get validation loss and accuracy.\n",
    "\n",
    "**Note:** We use `model.eval()` to enable evaluation mode of the model. This will stop calculating the running estimate of mean and variance of data. Using instead just the mean and variance computed while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> float:\n",
    "    # \n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            indx_target = target.clone()\n",
    "            data = data.to(train_config.device)\n",
    "\n",
    "            target = target.to(train_config.device)\n",
    "\n",
    "            output = model(data)\n",
    "            # add loss for each mini batch\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "\n",
    "            # get probability score using softmax\n",
    "            prob = F.softmax(output, dim=1)\n",
    "\n",
    "            # get the index of the max probability\n",
    "            pred = prob.data.max(dim=1)[1] \n",
    "\n",
    "            # add correct prediction count\n",
    "            count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "        # average over number of mini-batches\n",
    "        test_loss = test_loss / len(test_loader)  \n",
    "\n",
    "        # average over number of dataset\n",
    "        accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "\n",
    "        print(\n",
    "            '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "            )\n",
    "        )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Main</font><a name=\"main\"></a>\n",
    "\n",
    "\n",
    "Here, we use the configuration parameters defined above and start  training. \n",
    "\n",
    "1. Set up system parameters like CPU/GPU, number of threads etc.\n",
    "1. Load the data using dataloaders.\n",
    "1. Create an instance of the LeNet model.\n",
    "1. Specify optimizer to use.\n",
    "1. Set up variables to track loss and accuracy and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lower batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 2\n",
    "        epoch_num_to_set = 10\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        epochs_count=epoch_num_to_set,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # trainig time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [3200/60000] Loss: 2.305465 Acc: 0.0625\n",
      "Train Epoch: 0 [6400/60000] Loss: 2.244925 Acc: 0.2500\n",
      "Train Epoch: 0 [9600/60000] Loss: 2.197242 Acc: 0.2812\n",
      "Train Epoch: 0 [12800/60000] Loss: 1.346075 Acc: 0.4688\n",
      "Train Epoch: 0 [16000/60000] Loss: 1.115211 Acc: 0.5938\n",
      "Train Epoch: 0 [19200/60000] Loss: 1.062492 Acc: 0.7812\n",
      "Train Epoch: 0 [22400/60000] Loss: 0.789048 Acc: 0.7188\n",
      "Train Epoch: 0 [25600/60000] Loss: 0.939584 Acc: 0.5000\n",
      "Train Epoch: 0 [28800/60000] Loss: 0.688344 Acc: 0.6562\n",
      "Train Epoch: 0 [32000/60000] Loss: 0.678118 Acc: 0.6562\n",
      "Train Epoch: 0 [35200/60000] Loss: 0.911697 Acc: 0.6250\n",
      "Train Epoch: 0 [38400/60000] Loss: 0.563300 Acc: 0.8125\n",
      "Train Epoch: 0 [41600/60000] Loss: 0.616234 Acc: 0.7500\n",
      "Train Epoch: 0 [44800/60000] Loss: 0.867948 Acc: 0.6875\n",
      "Train Epoch: 0 [48000/60000] Loss: 0.663870 Acc: 0.7812\n",
      "Train Epoch: 0 [51200/60000] Loss: 0.616560 Acc: 0.7500\n",
      "Train Epoch: 0 [54400/60000] Loss: 0.603447 Acc: 0.8125\n",
      "Train Epoch: 0 [57600/60000] Loss: 0.788919 Acc: 0.6875\n",
      "Elapsed 5.87s, 5.87 s/epoch, 0.00 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 0.6284, Accuracy: 7620/10000 (76%)\n",
      "\n",
      "Total time: 6.45, Best Loss: 0.628\n",
      "Train Epoch: 0 [3200/60000] Loss: 1.934992 Acc: 0.6250\n",
      "Train Epoch: 0 [6400/60000] Loss: 1.114923 Acc: 0.6562\n",
      "Train Epoch: 0 [9600/60000] Loss: 0.950495 Acc: 0.7188\n",
      "Train Epoch: 0 [12800/60000] Loss: 0.812709 Acc: 0.6562\n",
      "Train Epoch: 0 [16000/60000] Loss: 0.641222 Acc: 0.7500\n",
      "Train Epoch: 0 [19200/60000] Loss: 0.563980 Acc: 0.8438\n",
      "Train Epoch: 0 [22400/60000] Loss: 0.560462 Acc: 0.7812\n",
      "Train Epoch: 0 [25600/60000] Loss: 0.638379 Acc: 0.7500\n",
      "Train Epoch: 0 [28800/60000] Loss: 0.525539 Acc: 0.8125\n",
      "Train Epoch: 0 [32000/60000] Loss: 0.511593 Acc: 0.8438\n",
      "Train Epoch: 0 [35200/60000] Loss: 0.574215 Acc: 0.7812\n",
      "Train Epoch: 0 [38400/60000] Loss: 0.451060 Acc: 0.8125\n",
      "Train Epoch: 0 [41600/60000] Loss: 0.456532 Acc: 0.8438\n",
      "Train Epoch: 0 [44800/60000] Loss: 0.534253 Acc: 0.8750\n",
      "Train Epoch: 0 [48000/60000] Loss: 0.537594 Acc: 0.7500\n",
      "Train Epoch: 0 [51200/60000] Loss: 0.398064 Acc: 0.8125\n",
      "Train Epoch: 0 [54400/60000] Loss: 0.395627 Acc: 0.8750\n",
      "Train Epoch: 0 [57600/60000] Loss: 0.478635 Acc: 0.8438\n",
      "Elapsed 5.83s, 5.83 s/epoch, 0.00 s/batch, ets 0.00s\n",
      "\n",
      "Test set: Average loss: 0.4400, Accuracy: 8419/10000 (84%)\n",
      "\n",
      "Total time: 6.42, Best Loss: 0.440\n"
     ]
    }
   ],
   "source": [
    "model = LeNet()\n",
    "modelBN = LeNetBN() \n",
    "\n",
    "model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main(model)\n",
    "\n",
    "modelBN, epoch_train_loss_bn, epoch_train_acc_bn, epoch_test_loss_bn, epoch_test_acc_bn = main(modelBN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">10. Plot Loss</font> <a name=\"plot-loss\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, 'r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, 'b', label=\"validation loss\")\n",
    "\n",
    "plt.plot(x, epoch_train_loss_bn, 'r--', label=\"train loss with BN\")\n",
    "plt.plot(x, epoch_test_loss_bn, 'b--',label=\"validation loss with BN\")\n",
    "\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above curves show that when we use Batch Normalization, the training converges faster."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:blue\">Miscellaneous: Calculate Mean and Standard Deviation of Fashion MNIST </font> <a name=\"misc\"></a>\n",
    "\n",
    "Ideally, we should not use the same mean and standard deviation for Fashion MNIST and MNIST. Refrain, even when you find many continuing to do this, simply because it does not have a profound effect on the results.\n",
    "\n",
    "Let us find  the mean and standard deviation for Fashion MNIST and use it instead of MNIST.\n",
    "\n",
    "We need to simply find the mean and standard deviation of the whole dataset. So, we load the dataset and then use the functions given below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.Size([60000, 28, 28])\n",
      "tensor(0.2860)\n",
      "tensor(0.3530)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "train_transform = transforms.Compose([transforms.ToTensor()])\n",
    "train_set = torchvision.datasets.FashionMNIST(root=\"../../../../data/Fasion_MNIST/\", train=True, download=False, transform=train_transform)\n",
    "print(type(train_set.data))\n",
    "print(train_set.data.shape)\n",
    "print(train_set.data.float().mean()/255)\n",
    "print(train_set.data.float().std()/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
