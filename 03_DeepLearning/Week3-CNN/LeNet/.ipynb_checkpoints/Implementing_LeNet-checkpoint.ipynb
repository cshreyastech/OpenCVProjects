{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Table of contents</font>\n",
    "\n",
    "- [LeNet5 Architecture](#lenet)\n",
    "- [Display the Network](#display)\n",
    "- [Get the MNIST Data](#get-data)\n",
    "- [System Configuration](#sys-config)\n",
    "- [Training Configuration](#train-config)\n",
    "- [System Setup](#sys-setup)\n",
    "- [Training](#training)\n",
    "- [Validation](#validation)\n",
    "- [Main function](#main)\n",
    "- [Plot Loss](#plot-loss)\n",
    "- [Plot Accuracy](#plot-acc)\n",
    "- [Save the Model Parameters](#save-model)\n",
    "- [Load the Model Parameters](#load-model)\n",
    "- [Model Prediction](#predict)\n",
    "- [Run Inference on Sample Images](#infer)\n",
    "- [References](#refs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">Convolutional Neural Networks </font>\n",
    "\n",
    "In this notebook, we will construct the LeNet architecture and, use the MNIST dataset to train it.\n",
    "\n",
    "\n",
    "It was in 1998 that Yann LeCun, Leon Bottou, Yosuha Bengio and Patrick Haffner first proposed this neural network architecture for handwritten and machine-printed character recognition.\n",
    "\n",
    "Follow this notebook to get familiar with the different layers involved in creating a CNN, and learn to use it oto create such a network. The training pipeline is similar to the MLP one we did last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # one of the best graphics library for python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "from typing import Iterable, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">1. LeNet5 Architecture</font><a name=\"lenet\"></a>\n",
    "\n",
    "This network has two convolutional layers and three fully connected layers.\n",
    "\n",
    "The model architecture has been divided into 2 parts:\n",
    "\n",
    "\n",
    "\n",
    "1. **`body`**: This implements the Convolutional part of the network, which consists of the `2` convolutional layers. Each convolutional layer is followed by a pooling layer. It also works as a feature extractor, in classical Machine Learning terms.\n",
    "1. **`head`**: This implements the fully-connected part of the network. Consists of `3` fully-connected layers, with the last layer having the 10 output classes. It also works  as a classifier.\n",
    "\n",
    "\n",
    "Finally, after creating the network, we also define the forward function which is executed when we pass an image through the network.\n",
    "\n",
    "### <font style=\"color:green\">Convolutional Layer Function Syntax </font>\n",
    "\n",
    "```\n",
    "torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')\n",
    "```\n",
    "Where,\n",
    "\n",
    "- **`in_channels`**: number of input channels. For example, for colored image inputs, `in_channel` must be `3`. If `out_channels` of the first `conv2d` is `6` then `in_channels` of the second `conv2d` layer must be `6`.\n",
    "\n",
    "- **`out_channel`:**  number of filters.\n",
    "\n",
    "- **`kernel_size`:** `int` or `tuple of int`. If it is `int`,  height and width will be the same. If it is a `tuple of int`, the first element will be the height (number of rows) of filter, while second element denotes its  width (number of columns) of the filter.\n",
    "\n",
    "\n",
    "- **`padding`:** padding can also be `int` or `tuple of int`. As in `kernel_size`, if it is `int` same padding will be done across the height and width.  The default is zero padding.\n",
    "\n",
    "At this point, do not consider other  argumentsas of. To know more, click [here](https://pytorch.org/docs/stable/nn.html#torch.nn.Conv2d).\n",
    "\n",
    "**Note:** There is no activation after the last linear layer. So during inference, if we want probability as the output, we need to pass the model output through `softmax`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # convolution layers\n",
    "        self._body = nn.Sequential(\n",
    "            # n_out = floor((n_in + 2*p - k) / s) + 1\n",
    "            # First convolution Layer\n",
    "            # input size = (32, 32), output size = (28, 28)\n",
    "            # floor((32 + 2 * 0 - 5) / 1) + 1 = 28\n",
    "            nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            # Max pool 2-d\n",
    "            # floor((28 + 2 * 0 - 2) / 2) + 1 = 14\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            \n",
    "            # Second convolution layer\n",
    "            # input size = (14, 14), output size = (10, 10)\n",
    "            # floor((14 + 2 * 0 - 5) / 1) + 1 = 10\n",
    "            nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5),\n",
    "            nn.ReLU(inplace=True),\n",
    "            # floor((10 + 2 * 0 - 2) / 2) + 1 = 5\n",
    "            nn.MaxPool2d(kernel_size=2),\n",
    "            # output size = (5, 5)\n",
    "        )\n",
    "        \n",
    "        # Fully connected layers\n",
    "        self._head = nn.Sequential(\n",
    "            # First fully connected layer\n",
    "            # in_features = total number of weights in last conv layer = 16 * 5 * 5\n",
    "            nn.Linear(in_features=16 * 5 * 5, out_features=120), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # second fully connected layer\n",
    "            # in_features = output of last linear layer = 120 \n",
    "            nn.Linear(in_features=120, out_features=84), \n",
    "            \n",
    "            # ReLU activation\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            # Third fully connected layer. It is also output layer\n",
    "            # in_features = output of last linear layer = 84\n",
    "            # and out_features = number of classes = 10 (MNIST data 0-9)\n",
    "            nn.Linear(in_features=84, out_features=10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # apply feature extractor\n",
    "        x = self._body(x)\n",
    "        # flatten the output of conv layers\n",
    "        # dimension should be batch_size * number_of weights_in_last conv_layer\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        # apply classification head\n",
    "        x = self._head(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">2. Display the Network</font><a name=\"display\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (_body): Sequential(\n",
      "    (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (_head): Sequential(\n",
      "    (0): Linear(in_features=400, out_features=120, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=120, out_features=84, bias=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): Linear(in_features=84, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lenet5_model = LeNet5()\n",
    "print(lenet5_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "## <font style=\"color:green\">3. Get MNIST Data</font><a name=\"get-data\"></a>\n",
    "\n",
    "Load the train and test data, using the dataloader class in PyTorch. The dataloader gives an iterator that spits out batches of data, when asked. Also, transform the data as required, using the transforms.Compose function:\n",
    "\n",
    "Load the train and test data, using the dataloader class in PyTorch. The dataloader gives an iterator that spits out batches of data, when asked. Also, transform the data as required, using the <a href=\"https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Compose\" target=\"_blank\">transforms.Compose</a>\n",
    "function:\n",
    "\n",
    "```python\n",
    "train_test_transforms = transforms.Compose([\n",
    "        # Resize to 32X32\n",
    "        transforms.Resize((32, 32)),\n",
    "        # this re-scales image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean (0.1307) and divide by variance (0.3081)\n",
    "        transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ])\n",
    "```\n",
    "\n",
    "**Do the  following on the input data:**\n",
    "\n",
    "1. Resize to `32 x 32` to match the  the input size to the model. For more details of` transforms.Resize`, <a href=\"https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Resize\" target=\"_blank\">click here</a>.\n",
    "\n",
    "2. Rescale image tensor values between `0-1`. Divide each pixel by `255`. For  more details of `transforms.ToTensor`, <a href=\"https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.ToTensor\" target=\"_blank\">click here</a>.\n",
    "\n",
    "3. Normalize the data, by subtracting mean and dividing by variance. This is also known as standardization. For more details of `transforms.Normalize`, <a href=\"https://pytorch.org/vision/stable/transforms.html#torchvision.transforms.Normalize\" target=\"_blank\">click here</a>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(batch_size, data_root='data', num_workers=1):\n",
    "    \n",
    "    \n",
    "    train_test_transforms = transforms.Compose([\n",
    "        # Resize to 32X32\n",
    "        transforms.Resize((32, 32)),\n",
    "        # this re-scales image tensor values between 0-1. image_tensor /= 255\n",
    "        transforms.ToTensor(),\n",
    "        # subtract mean (0.1307) and divide by variance (0.3081).\n",
    "        # This mean and variance is calculated on training data (verify yourself)\n",
    "        transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ])\n",
    "    \n",
    "    # train dataloader\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(root=data_root, train=True, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    \n",
    "    # test dataloader\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(root=data_root, train=False, download=False, transform=train_test_transforms),\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">4. System Configuration</font><a name=\"sys-config\"></a>\n",
    "\n",
    "It is best to have the configuration parameters in separate files. Here, we use a single notebook, therefore let’s start by creating a class for it, and later see how to **structure the project** such that separate files can be maintained.\n",
    "\n",
    "\n",
    "In **`SystemConfiguration`** class, we defined a few attributes to get reproducible results, every time we run the notebook. Generally, this is a good practice. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class SystemConfiguration:\n",
    "    '''\n",
    "    Describes the common system setting needed for reproducible training\n",
    "    '''\n",
    "    seed: int = 42  # seed number to set the state of all random number generators\n",
    "    cudnn_benchmark_enabled: bool = True  # enable CuDNN benchmark for the sake of performance\n",
    "    cudnn_deterministic: bool = True  # make cudnn deterministic (reproducible training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">5. Training Configuration</font><a name=\"train-config\"></a>\n",
    "\n",
    "In **`TrainingConfiguration`**  class,  we have specified the configuration parameters of the training process. We are already familiar with these configurations. This is also a good practice since you don't need to change the network architecture so often as you change the training parameters. So, keeping them in a separate file/class helps you keep your code modular and clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class TrainingConfiguration:\n",
    "    '''\n",
    "    Describes configuration of the training process\n",
    "    '''\n",
    "    batch_size: int = 32  # amount of data to pass through the network at each forward-backward iteration\n",
    "    epochs_count: int = 1  # number of times the whole dataset will be passed through the network\n",
    "    learning_rate: float = 0.01  # determines the speed of network's weights update\n",
    "    log_interval: int = 100  # how many batches to wait between logging training status\n",
    "    test_interval: int = 1  # how many epochs to wait before another test. Set to 1 to get val loss at each epoch\n",
    "    data_root: str = \"../resource/lib/publicdata/data\"  # folder to save MNIST data (default: data/mnist-data)\n",
    "    num_workers: int = 10  # number of concurrent processes used to prepare data\n",
    "    device: str = 'cuda'  # device to use for training.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">6. System Setup</font><a name=\"sys-setup\"></a>\n",
    "\n",
    "Let us define a function, **`setup_system`** that will check the `SystemConfiguration` attributes and update the system settings accordingly. For example, it sets the device to GPU/CPU depending on GPU availability on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_system(system_config: SystemConfiguration) -> None:\n",
    "    torch.manual_seed(system_config.seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.backends.cudnn_benchmark_enabled = system_config.cudnn_benchmark_enabled\n",
    "        torch.backends.cudnn.deterministic = system_config.cudnn_deterministic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">7. Training</font><a name=\"training\"></a>\n",
    "\n",
    "You are familiar with the training pipeline used in PyTorch. Follow the steps given below:\n",
    "\n",
    "1. Send the data to the required device ( CPU/GPU ).\n",
    "1. Make a forward pass using the forward method.\n",
    "1. Find the loss using the Cross_Entropy function.\n",
    "1. Find the gradients using the backward function.\n",
    "1. Update the weights using the optimizer.\n",
    "1. Find the accuracy of the model.\n",
    "\n",
    "Repeat the above for the specified number of epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    train_config: TrainingConfiguration, model: nn.Module, optimizer: torch.optim.Optimizer,\n",
    "    train_loader: torch.utils.data.DataLoader, epoch_idx: int\n",
    ") -> Tuple[float, float]:\n",
    "    \n",
    "    # change model in training mode\n",
    "    model.train()\n",
    "    \n",
    "    # to get batch loss\n",
    "    batch_loss = np.array([])\n",
    "    \n",
    "    # to get batch accuracy\n",
    "    batch_acc = np.array([])\n",
    "        \n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        \n",
    "        # clone target\n",
    "        indx_target = target.clone()\n",
    "        # send data to device (it is mandatory if GPU has to be used)\n",
    "        data = data.to(train_config.device)\n",
    "        # send target to device\n",
    "        target = target.to(train_config.device)\n",
    "\n",
    "        # reset parameters gradient to zero\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward pass to the model\n",
    "        output = model(data)\n",
    "        \n",
    "        # cross entropy loss\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # find gradients w.r.t training parameters\n",
    "        loss.backward()\n",
    "        # Update parameters using gradients\n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = np.append(batch_loss, [loss.item()])\n",
    "        \n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "            \n",
    "        # get the index of the max probability\n",
    "        pred = prob.data.max(dim=1)[1]  \n",
    "                        \n",
    "        # correct prediction\n",
    "        correct = pred.cpu().eq(indx_target).sum()\n",
    "            \n",
    "        # accuracy\n",
    "        acc = float(correct) / float(len(data))\n",
    "        \n",
    "        batch_acc = np.append(batch_acc, [acc])\n",
    "\n",
    "        if batch_idx % train_config.log_interval == 0 and batch_idx > 0:              \n",
    "            print(\n",
    "                'Train Epoch: {} [{}/{}] Loss: {:.6f} Acc: {:.4f}'.format(\n",
    "                    epoch_idx, batch_idx * len(data), len(train_loader.dataset), loss.item(), acc\n",
    "                )\n",
    "            )\n",
    "            \n",
    "    epoch_loss = batch_loss.mean()\n",
    "    epoch_acc = batch_acc.mean()\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">8. Validation</font><a name=\"validation\"></a>\n",
    "\n",
    "After every few epochs, you must do **`validation`** with the trained model and `test_loader` in order to get validation loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    train_config: TrainingConfiguration,\n",
    "    model: nn.Module,\n",
    "    test_loader: torch.utils.data.DataLoader,\n",
    ") -> Tuple[float, float]:\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    count_corect_predictions = 0\n",
    "    \n",
    "    # turn off gradient-computation\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for data, target in test_loader:\n",
    "            indx_target = target.clone()\n",
    "            data = data.to(train_config.device)\n",
    "\n",
    "            target = target.to(train_config.device)\n",
    "\n",
    "            output = model(data)\n",
    "            # add loss for each mini batch\n",
    "            test_loss += F.cross_entropy(output, target).item()\n",
    "\n",
    "            # get probability score using softmax\n",
    "            prob = F.softmax(output, dim=1)\n",
    "\n",
    "            # get the index of the max probability\n",
    "            pred = prob.data.max(dim=1)[1] \n",
    "\n",
    "            # add correct prediction count\n",
    "            count_corect_predictions += pred.cpu().eq(indx_target).sum()\n",
    "\n",
    "        # average over number of mini-batches\n",
    "        test_loss = test_loss / len(test_loader)  \n",
    "\n",
    "        # average over number of dataset\n",
    "        accuracy = 100. * count_corect_predictions / len(test_loader.dataset)\n",
    "\n",
    "        print(\n",
    "            '\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, count_corect_predictions, len(test_loader.dataset), accuracy\n",
    "            )\n",
    "        )\n",
    "    return test_loss, accuracy/100.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">9. Main</font><a name=\"main\"></a>\n",
    "\n",
    "\n",
    "In this section of code, we use the configuration parameters defined above and start training.\n",
    "\n",
    "1. Set up system parameters like CPU/GPU, number of threads etc.\n",
    "1. Load the data using dataloaders.\n",
    "1. Create an instance of the LeNet model.\n",
    "1. Specify optimizer to use.\n",
    "1. Set up variables to track loss and accuracy and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(system_configuration=SystemConfiguration(), training_configuration=TrainingConfiguration()):\n",
    "    \n",
    "    # system configuration\n",
    "    setup_system(system_configuration)\n",
    "\n",
    "    # batch size\n",
    "    batch_size_to_set = training_configuration.batch_size\n",
    "    # num_workers\n",
    "    num_workers_to_set = training_configuration.num_workers\n",
    "    # epochs\n",
    "    epoch_num_to_set = training_configuration.epochs_count\n",
    "\n",
    "    # if GPU is available use training config, \n",
    "    # else lower batch_size, num_workers and epochs count\n",
    "    if torch.cuda.is_available():\n",
    "        device = \"cuda\"\n",
    "    else:\n",
    "        device = \"cpu\"\n",
    "        batch_size_to_set = 16\n",
    "        num_workers_to_set = 2\n",
    "        epoch_num_to_set = 5\n",
    "\n",
    "    # data loader\n",
    "    train_loader, test_loader = get_data(\n",
    "        batch_size=batch_size_to_set,\n",
    "        data_root=training_configuration.data_root,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "    \n",
    "    # Update training configuration\n",
    "    training_configuration = TrainingConfiguration(\n",
    "        device=device,\n",
    "        epochs_count=epoch_num_to_set,\n",
    "        batch_size=batch_size_to_set,\n",
    "        num_workers=num_workers_to_set\n",
    "    )\n",
    "\n",
    "    # initiate model\n",
    "    model = LeNet5()\n",
    "        \n",
    "    # send model to device (GPU/CPU)\n",
    "    model.to(training_configuration.device)\n",
    "\n",
    "    # optimizer\n",
    "    optimizer = optim.SGD(\n",
    "        model.parameters(),\n",
    "        lr=training_configuration.learning_rate\n",
    "    )\n",
    "\n",
    "    best_loss = torch.tensor(np.inf)\n",
    "    \n",
    "    # epoch train/test loss\n",
    "    epoch_train_loss = np.array([])\n",
    "    epoch_test_loss = np.array([])\n",
    "    \n",
    "    # epoch train/test accuracy\n",
    "    epoch_train_acc = np.array([])\n",
    "    epoch_test_acc = np.array([])\n",
    "    \n",
    "    # training time measurement\n",
    "    t_begin = time.time()\n",
    "    for epoch in range(training_configuration.epochs_count):\n",
    "        \n",
    "        train_loss, train_acc = train(training_configuration, model, optimizer, train_loader, epoch)\n",
    "        \n",
    "        epoch_train_loss = np.append(epoch_train_loss, [train_loss])\n",
    "        \n",
    "        epoch_train_acc = np.append(epoch_train_acc, [train_acc])\n",
    "\n",
    "        elapsed_time = time.time() - t_begin\n",
    "        speed_epoch = elapsed_time / (epoch + 1)\n",
    "        speed_batch = speed_epoch / len(train_loader)\n",
    "        eta = speed_epoch * training_configuration.epochs_count - elapsed_time\n",
    "        \n",
    "        print(\n",
    "            \"Elapsed {:.2f}s, {:.2f} s/epoch, {:.2f} s/batch, ets {:.2f}s\".format(\n",
    "                elapsed_time, speed_epoch, speed_batch, eta\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if epoch % training_configuration.test_interval == 0:\n",
    "            current_loss, current_accuracy = validate(training_configuration, model, test_loader)\n",
    "            \n",
    "            epoch_test_loss = np.append(epoch_test_loss, [current_loss])\n",
    "        \n",
    "            epoch_test_acc = np.append(epoch_test_acc, [current_accuracy])\n",
    "            \n",
    "            if current_loss < best_loss:\n",
    "                best_loss = current_loss\n",
    "                \n",
    "    print(\"Total time: {:.2f}, Best Loss: {:.3f}\".format(time.time() - t_begin, best_loss))\n",
    "    \n",
    "    return model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/hd/disk2/virtual_envs/pytorch_env/lib/python3.10/site-packages/torch/cuda/__init__.py:129: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Dataset not found. You can use download=True to download it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 24\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(system_configuration, training_configuration)\u001b[0m\n\u001b[1;32m     21\u001b[0m     epoch_num_to_set \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# data loader\u001b[39;00m\n\u001b[0;32m---> 24\u001b[0m train_loader, test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mget_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size_to_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_root\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_configuration\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_workers_to_set\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Update training configuration\u001b[39;00m\n\u001b[1;32m     31\u001b[0m training_configuration \u001b[38;5;241m=\u001b[39m TrainingConfiguration(\n\u001b[1;32m     32\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     33\u001b[0m     epochs_count\u001b[38;5;241m=\u001b[39mepoch_num_to_set,\n\u001b[1;32m     34\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size_to_set,\n\u001b[1;32m     35\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnum_workers_to_set\n\u001b[1;32m     36\u001b[0m )\n",
      "Cell \u001b[0;32mIn[8], line 16\u001b[0m, in \u001b[0;36mget_data\u001b[0;34m(batch_size, data_root, num_workers)\u001b[0m\n\u001b[1;32m      4\u001b[0m train_test_transforms \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;66;03m# Resize to 32X32\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.1307\u001b[39m, ), (\u001b[38;5;241m0.3081\u001b[39m, ))\n\u001b[1;32m     12\u001b[0m ])\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# train dataloader\u001b[39;00m\n\u001b[1;32m     15\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mdatasets\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMNIST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_root\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_test_transforms\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     17\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     18\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnum_workers\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# test dataloader\u001b[39;00m\n\u001b[1;32m     23\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     24\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mMNIST(root\u001b[38;5;241m=\u001b[39mdata_root, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtrain_test_transforms),\n\u001b[1;32m     25\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m     26\u001b[0m     shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     27\u001b[0m     num_workers\u001b[38;5;241m=\u001b[39mnum_workers\n\u001b[1;32m     28\u001b[0m )\n",
      "File \u001b[0;32m/mnt/hd/disk2/virtual_envs/pytorch_env/lib/python3.10/site-packages/torchvision/datasets/mnist.py:103\u001b[0m, in \u001b[0;36mMNIST.__init__\u001b[0;34m(self, root, train, transform, target_transform, download)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownload()\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_exists():\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset not found. You can use download=True to download it\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtargets \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_data()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Dataset not found. You can use download=True to download it"
     ]
    }
   ],
   "source": [
    "model, epoch_train_loss, epoch_train_acc, epoch_test_loss, epoch_test_acc = main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">10. Plot Loss</font><a name=\"plot-loss\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_loss, color='r', label=\"train loss\")\n",
    "plt.plot(x, epoch_test_loss, color='b', label=\"validation loss\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">11. Plot Accuracy</font><a name=\"plot-acc\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "x = range(len(epoch_train_loss))\n",
    "\n",
    "\n",
    "plt.figure\n",
    "plt.plot(x, epoch_train_acc, color='r', label=\"train accuracy\")\n",
    "plt.plot(x, epoch_test_acc, color='b', label=\"validation accuracy\")\n",
    "plt.xlabel('epoch no.')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='center right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">12. Save the Model Parameters</font><a name=\"save-model\"></a>\n",
    "\n",
    "After training the model, you need to save it.  Later, use it for inference or to resume training from where you paused it.  ( Eg:, When you use free services like Google Colab etc.)\n",
    "\n",
    "While saving or loading the model, the most important concept to understand is `state_dict`. The model, as you know, consists of parameters learned during training. These can now be accessed using the `model.parameters()` method. Also, there are some optimizer parameters.  These carry information on hyperparameters like learning rate, optimizer used etc.\n",
    "\n",
    "\n",
    "All the above information is stored in the form of `state_dict`s. There are separate state_dicts for model parameters (`model.state_dict()`) and optimizer (`optimizer.state_dict()`). \n",
    "\n",
    "\n",
    "So, if you want to save the model for inference, save the state_dict of the model only. However, if you want to resume training from some checkpoint, you need to save the optimizer's `state_dict` as well (more discussion on checkpoints later).\n",
    "\n",
    "\n",
    "Save the model using the code below:\n",
    "\n",
    "**Note:** It's a good practice to save the `CPU` compatible model. So before saving, send the model to the `CPU` using `model.to('cpu')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = 'models'\n",
    "if not os.path.exists(models):\n",
    "    os.makedirs(models)\n",
    "    \n",
    "model_file_name = 'lenet5_mnist.pt'\n",
    "\n",
    "model_path = os.path.join(models, model_file_name)\n",
    "\n",
    "# make sure you transfer the model to cpu.\n",
    "model.to('cpu')\n",
    "\n",
    "# save the state_dict\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">13. Load the Model Parameters </font><a name=\"load-model\"></a>\n",
    "After saving the model's state_dict, you can load the parameters into the model using similar functions. \n",
    "\n",
    "1. Create an instance of the model class.\n",
    "\n",
    "1. Load the parameters by using `torch.load(model_path)`.\n",
    "\n",
    "1. Load the parameters inside the model using `model.load_state_dict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the model\n",
    "lenet5_mnist = LeNet5()\n",
    "\n",
    "# loading the model and getting model parameters by using load_state_dict\n",
    "lenet5_mnist.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">14. Model Prediction</font><a name=\"predict\"></a>\n",
    "\n",
    "Use the trained model to perform inference on new data. Just do a forward pass through the network, and use  softmax on the output. This will give us a probability score of the prediction.\n",
    "\n",
    "\n",
    "Finally, we find the argmax of the output. It tells us which class  the prediction belongs to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, train_config, batch_input):\n",
    "    \n",
    "    # turn off gradient-computation\n",
    "    with torch.no_grad():\n",
    "    \n",
    "        # send model to cpu/cuda according to your system configuration\n",
    "        model.to(train_config.device)\n",
    "\n",
    "        # it is important to do model.eval() before prediction\n",
    "        model.eval()\n",
    "\n",
    "        data = batch_input.to(train_config.device)\n",
    "\n",
    "        output = model(data)\n",
    "\n",
    "        # get probability score using softmax\n",
    "        prob = F.softmax(output, dim=1)\n",
    "\n",
    "        # get the max probability\n",
    "        pred_prob = prob.data.max(dim=1)[0]\n",
    "\n",
    "        # get the index of the max probability\n",
    "        pred_index = prob.data.max(dim=1)[1]\n",
    "    \n",
    "    return pred_index.cpu().numpy(), pred_prob.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font style=\"color:green\">15. Run Inference on Sample Images </font><a name=\"infer\"></a>\n",
    "\n",
    "For prediction, we need to transform the data like we did for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "train_config = TrainingConfiguration()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    train_config.device = \"cuda\"\n",
    "else:\n",
    "    train_config.device = \"cpu\"\n",
    "\n",
    "# load test data without image transformation\n",
    "test = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=train_config.data_root, train=False, download=True, \n",
    "                   transform=transforms.functional.to_tensor),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "image_transforms = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307, ), (0.3081, ))\n",
    "    ])\n",
    "\n",
    "test_trans = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST(root=train_config.data_root, train=False, download=True, transform=image_transforms),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=1\n",
    "    )\n",
    "\n",
    "for data, _ in test_trans:\n",
    "    # pass the loaded model\n",
    "    pred, prob = prediction(lenet5_mnist, train_config, data)\n",
    "    break\n",
    "    \n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (3, 3)\n",
    "for images, _ in test:\n",
    "    for i, img in enumerate(images):\n",
    "        img = transforms.functional.to_pil_image(img)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.gca().set_title('Prediction: {0}, Prob: {1:.2}'.format(pred[i], prob[i]))\n",
    "        plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style=\"color:blue\">References</font><a name=\"refs\"></a>\n",
    "\n",
    "1. https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "1. https://pytorch.org/tutorials/beginner/saving_loading_models.html"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
